{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# In this notebook file, we will test each function of the CAS preparation",
   "id": "fd3cd7a45b0692fe"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-06-04T19:19:03.618477Z",
     "start_time": "2024-06-04T19:19:03.604013Z"
    }
   },
   "source": [
    "import CAS_Cropping.planted_solutions_workflow as planted_workflow\n",
    "from pathlib import Path\n",
    "import CAS_Cropping.ferm_utils as feru\n",
    "import CAS_Cropping.csa_utils as csau\n",
    "import CAS_Cropping.var_utils as varu\n",
    "import openfermion as of\n",
    "import numpy as np\n",
    "from CAS_Cropping.sdstate import *\n",
    "from itertools import product\n",
    "import random\n",
    "from pathlib import Path\n",
    "from itertools import product\n",
    "import h5py\n",
    "import sys\n",
    "from CAS_Cropping.matrix_utils import construct_orthogonal\n",
    "import pickle\n",
    "import CAS.dmrghandler.src.dmrghandler.pyscf_wrappers\n",
    "import CAS.dmrghandler.src.dmrghandler.dmrg_calc_prepare\n",
    "import CAS.dmrghandler.src.dmrghandler.qchem_dmrg_calc\n",
    "import CAS.dmrghandler.src.dmrghandler as dmrghandler\n",
    "import tensorflow as tf\n",
    "import pyscf.tools.fcidump\n",
    "import scipy\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "### Parameters\n",
    "tol = 1e-5\n",
    "balance_strength = 2\n",
    "save = False\n",
    "# Number of spatial orbitals in a block\n",
    "block_size = 3\n",
    "# Number of electrons per block\n",
    "ne_per_block = 6\n",
    "# +- difference in number of electrons per block\n",
    "ne_range = 0\n",
    "# Number of killer operators for each CAS block\n",
    "n_killer = 3\n",
    "# Running Full CI to check compute the ground state, takes exponentially amount of time to execute\n",
    "FCI = False\n",
    "# Checking symmetries of the planted Hamiltonian, very costly\n",
    "check_symmetry = False\n",
    "# Concatenate the states in each block to compute the ground state solution\n",
    "check_state = False"
   ],
   "outputs": [],
   "execution_count": 56
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-04T19:26:30.674771Z",
     "start_time": "2024-06-04T19:26:30.668512Z"
    }
   },
   "cell_type": "code",
   "source": [
    "fcidump_filename = \"test_fcidumps/fcidump.2_co2_6-311++G__\"\n",
    "fcidump_output_path = \"fcidumps_catalysts_planted_solutions\""
   ],
   "id": "bc34b29a010cbed7",
   "outputs": [],
   "execution_count": 78
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-04T19:35:30.829772Z",
     "start_time": "2024-06-04T19:35:30.734962Z"
    }
   },
   "cell_type": "code",
   "source": [
    "(\n",
    "one_body_tensor,\n",
    "two_body_tensor,\n",
    "nuc_rep_energy,\n",
    "num_orbitals,\n",
    "num_spin_orbitals,\n",
    "num_electrons,\n",
    "two_S,\n",
    "two_Sz,\n",
    "orb_sym,\n",
    "extra_attributes,\n",
    ") = dmrghandler.dmrg_calc_prepare.load_tensors_from_fcidump(data_file_path=fcidump_filename, molpro_orbsym_convention=True)\n",
    "spin_orbs = 2*num_orbitals\n",
    "spatial_orbs = num_orbitals\n",
    "print(f\"Spatial orbs: {spatial_orbs}, two_S: {two_S}, two_Sz: {two_Sz}, # of electrons: {num_electrons}\")"
   ],
   "id": "c05dd5eb8c81526a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing test_fcidumps/fcidump.2_co2_6-311++G__\n",
      "Spatial orbs: 6, two_S: 0, two_Sz: 0, # of electrons: 8\n"
     ]
    }
   ],
   "execution_count": 82
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-04T19:36:03.118067Z",
     "start_time": "2024-06-04T19:36:03.110904Z"
    }
   },
   "cell_type": "code",
   "source": "assert one_body_tensor.shape[0] == spatial_orbs, \"Tensor not in spatial orbital\"",
   "id": "de5cb016ec6b80b5",
   "outputs": [],
   "execution_count": 84
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-04T19:19:04.151705Z",
     "start_time": "2024-06-04T19:19:04.148884Z"
    }
   },
   "cell_type": "code",
   "source": [
    "Hobt = one_body_tensor\n",
    "Htbt = two_body_tensor\n",
    "Hobt -= 0.5 * np.einsum(\"prrq->pq\", Htbt.copy())\n",
    "Htbt *= 0.5\n",
    "H = (Hobt, Htbt)"
   ],
   "id": "964a48bd2f30afb7",
   "outputs": [],
   "execution_count": 59
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Test block construction",
   "id": "bdaeed158c9b8251"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-04T19:19:04.773453Z",
     "start_time": "2024-06-04T19:19:04.766570Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def test_block_construction(size, orbs):\n",
    "    blocks = planted_workflow.construct_blocks(size, orbs, False)\n",
    "    num_same_blocks = orbs // size\n",
    "    last_block_size = orbs - num_same_blocks * size\n",
    "    block_count = 0\n",
    "    for i in range(len(blocks)):\n",
    "        if i != len(blocks) - 1:\n",
    "            block_count += 1\n",
    "            assert len(blocks[i]) == size, \"Block size mismatch\"\n",
    "        else:\n",
    "            assert len(blocks[i]) == size or len(blocks[i]) == last_block_size, \"Last block size mismatch\"\n",
    "\n",
    "test_block_construction(block_size, spatial_orbs)\n",
    "k = planted_workflow.construct_blocks(block_size, spatial_orbs)"
   ],
   "id": "8084ae8858441332",
   "outputs": [],
   "execution_count": 60
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Test getting param num",
   "id": "6ecefdc17aa72ea9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-04T19:19:05.603612Z",
     "start_time": "2024-06-04T19:19:05.600470Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def test_get_param_num(spatial_orbs, k):\n",
    "    upnum, casnum, pnum = planted_workflow.get_param_num(spatial_orbs, k, complex=False)\n",
    "    block_size = len(k[0])\n",
    "    assert casnum % (block_size ** 2) == 0, \"parameter num failed\"\n",
    "    assert upnum == int(spatial_orbs * (spatial_orbs - 1) / 2), \"Upper triangular parameters num failed\"\n",
    "test_get_param_num(spatial_orbs, k)\n",
    "upnum, casnum, pnum = planted_workflow.get_param_num(spatial_orbs, k, complex=False)"
   ],
   "id": "ec7816590e34589e",
   "outputs": [],
   "execution_count": 61
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Test getting truncated CAS tbt",
   "id": "c30a0513e8cd3a43"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-04T19:19:06.338361Z",
     "start_time": "2024-06-04T19:19:06.334278Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def test_truncated_cas_tbt(H, blocks: list[list[int]], casnum):\n",
    "    cas_obt, cas_tbt, cas_x = planted_workflow.get_truncated_cas_tbt(H, blocks, casnum)\n",
    "    for block_pair in product(blocks, blocks):\n",
    "        if block_pair[0] != block_pair[1]:\n",
    "            indices1 = block_pair[0]\n",
    "            indices2 = block_pair[1]\n",
    "            for pair in product(indices1, indices2):\n",
    "                assert cas_obt[pair[0], pair[1]] == 0, \"Truncation failed\"\n",
    "                assert cas_tbt[pair[0], pair[0], pair[1], pair[1]] == 0, \"Truncation failed\"\n",
    "\n",
    "test_truncated_cas_tbt(H, k, casnum)\n",
    "cas_obt, cas_tbt, cas_x = planted_workflow.get_truncated_cas_tbt(H, k, casnum)\n",
    "\n",
    "planted_sol = {}\n",
    "H_cas = [cas_obt, cas_tbt]\n",
    "cas_obt_copy = cas_obt.copy()\n",
    "cas_tbt_copy = cas_tbt.copy()"
   ],
   "id": "868b76f326a3ea5",
   "outputs": [],
   "execution_count": 62
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Test solve nums",
   "id": "fdbdbcc61a505551"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-04T19:19:07.530113Z",
     "start_time": "2024-06-04T19:19:07.401189Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def test_solve_nums(H_cas, k, num_electrons, ne_per_block = ne_per_block,\n",
    "                                    ne_range = ne_range, balance_t = balance_strength):\n",
    "    e_nums, states, E_cas = planted_workflow.solve_enums(H_cas, k, num_electrons, ne_per_block = ne_per_block,\n",
    "                                    ne_range = ne_range, balance_t = balance_strength)\n",
    "    \n",
    "    num_of_blocks = num_electrons // ne_per_block\n",
    "    remaining = num_electrons - num_of_blocks * ne_per_block\n",
    "    for i in range(len(e_nums)):\n",
    "        if i != len(e_nums)-1:\n",
    "            assert e_nums[i] == ne_per_block, \"# of electrons in each block is wrong\"\n",
    "        else:\n",
    "            assert e_nums[i] == ne_per_block or e_nums[i] == remaining, \"# of electrons in each block is wrong\"\n",
    "    \n",
    "    return e_nums, states, E_cas\n",
    "\n",
    "\n",
    "def test_tensor_changes(obt, obt_copy, tbt, tbt_copy):\n",
    "    if obt.all() == obt_copy.all():\n",
    "        assert \"Tensor hasn't been modified\"\n",
    "    if  tbt.all() == tbt_copy.all():\n",
    "        assert \"Tensor hasn't been modified\"\n",
    "    \n",
    "    obt_diff = obt - obt_copy\n",
    "    tbt_diff = tbt - tbt_copy\n",
    "    assert scipy.linalg.norm(obt_diff) > 1, \"Tensor change failed\" \n",
    "    assert scipy.linalg.norm(tbt_diff) > 1, \"Tensor change failed\" \n",
    "    \n",
    "    # We also want to test only the diagonals were modified.\n",
    "    indices = [i for i in range(obt.shape[0])]\n",
    "    \n",
    "    for pair in product(indices, indices):\n",
    "        if pair[0] != pair[1]:\n",
    "            assert obt_diff[pair[0], pair[1]] == 0, \"Non diagonal terms modified\"\n",
    "        if pair[0] == pair[1]:\n",
    "            assert obt_diff[pair[0], pair[1]] != 0, \"Diagonal terms not modified\"\n",
    "    \n",
    "    count_non_zero_in_tbt = 0\n",
    "    for pair in product(indices, indices, indices, indices):\n",
    "        if pair[0] == pair[1] and pair[2] == pair[3]:\n",
    "            if tbt_diff[pair[0], pair[1], pair[2], pair[3]] != 0:\n",
    "                count_non_zero_in_tbt += 1\n",
    "        else:\n",
    "            assert tbt_diff[pair[0], pair[1], pair[2], pair[3]] == 0, \"Non diagonal terms modified\"\n",
    "    \n",
    "    assert count_non_zero_in_tbt > 0, \"Diagonal terms in blocks have been modified\"\n",
    "    \n",
    "    \n",
    "e_nums, states, E_cas = test_solve_nums(H_cas, k, num_electrons, ne_per_block = ne_per_block,\n",
    "                                    ne_range = ne_range, balance_t = balance_strength)\n",
    "\n",
    "test_tensor_changes(cas_obt, cas_obt_copy, cas_tbt, cas_tbt_copy)"
   ],
   "id": "e58a3ab10298244e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ne within current block: 6\n",
      "E_min: -294.46613886008566 for orbs: [0, 1, 2]\n",
      "current state Energy: -294.4661388600851\n",
      "Ne within current block: 2\n",
      "E_min: -35.48504756736056 for orbs: [3, 4, 5]\n",
      "current state Energy: -35.485047567360596\n"
     ]
    }
   ],
   "execution_count": 63
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "print(f\"e_nums:{e_nums}\")\n",
    "print(f\"E_cas: {E_cas}\")\n",
    "sd_sol = sdstate()\n",
    "obt_2 = copy.deepcopy(cas_obt)\n",
    "tbt_2 = copy.deepcopy(cas_tbt)"
   ],
   "id": "4b8ff8cdded60fda"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Test killer term construction",
   "id": "e74e361b2c4cbf1a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-04T19:25:08.370282Z",
     "start_time": "2024-06-04T19:25:08.354993Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def test_killer_construction(k, e_nums, n = spatial_orbs, n_killer = n_killer):\n",
    "    killer_c, killer_obt, killer_tbt = planted_workflow.construct_killer(k, e_nums, n = spatial_orbs, n_killer = n_killer)\n",
    "    for pair in killer_obt.indices.numpy():\n",
    "        assert pair[0] == pair[1], \"Killer obt not diagonal\"\n",
    "    \n",
    "    for pair in killer_tbt.indices.numpy():\n",
    "        assert pair[0] == pair[1] and pair[2] == pair[3], \"Killer tbt not diagonal\"\n",
    "    \n",
    "test_killer_construction(k, e_nums, n = spatial_orbs, n_killer = n_killer)\n",
    "killer_c, killer_obt, killer_tbt = planted_workflow.construct_killer(k, e_nums, n = spatial_orbs, n_killer = n_killer)\n"
   ],
   "id": "ce0aeb53d6210f8c",
   "outputs": [],
   "execution_count": 76
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Test temporary .pkl file saving",
   "id": "e663dbd32af128ca"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-04T19:26:54.115180Z",
     "start_time": "2024-06-04T19:26:54.101245Z"
    }
   },
   "cell_type": "code",
   "source": [
    "planted_sol[\"E_min\"] = E_cas\n",
    "planted_sol[\"e_nums\"] = e_nums\n",
    "planted_sol[\"killer\"] = (killer_c, killer_obt, killer_tbt)\n",
    "planted_sol[\"k\"] = k\n",
    "planted_sol[\"casnum\"] = casnum\n",
    "planted_sol[\"pnum\"] = pnum\n",
    "planted_sol[\"upnum\"] = upnum\n",
    "planted_sol[\"spatial_orbs\"] = spatial_orbs\n",
    "planted_sol[\"cas_x\"] = cas_x\n",
    "planted_sol[\"sol\"] = states\n",
    "planted_sol[\"cas_obt\"] = cas_obt\n",
    "planted_sol[\"cas_tbt\"] = cas_tbt\n",
    "\n",
    "if check_state:\n",
    "    planted_sol[\"solution\"] = sd_sol\n",
    "\n",
    "ps_path = \"test_cas_planted_solutions/\"\n",
    "f_name = fcidump_filename.split(\".\")[1] + \".pkl\"\n",
    "print(ps_path +f_name)\n",
    "\n",
    "l = list(map(len, k))\n",
    "l = list(map(str, l))\n",
    "key = \"-\".join(l)\n",
    "print(key)\n",
    "if os.path.exists(ps_path + f_name):\n",
    "    with open(ps_path + f_name, 'rb') as handle:\n",
    "        dic = pickle.load(handle)\n",
    "else:\n",
    "    dic = {}\n",
    "\n",
    "with open(ps_path + f_name, 'wb') as handle:\n",
    "    dic[key] = planted_sol\n",
    "    pickle.dump(dic, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ],
   "id": "a036b82e309c0f7f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_cas_planted_solutions/2_co2_6-311++G__.pkl\n",
      "3-3\n"
     ]
    }
   ],
   "execution_count": 80
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Test loading Hamiltonians",
   "id": "6479bd5bf7a60622"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-04T19:40:42.842507Z",
     "start_time": "2024-06-04T19:40:42.800384Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def test_spatial_chem_to_phy(obt, tbt):\n",
    "    phy_obt, phy_tbt = planted_workflow.chem_spatial_orb_to_phys_spatial_orb(obt, tbt)\n",
    "    assert np.allclose(phy_tbt / 2, tbt), \"chem to phy indices wrong\""
   ],
   "id": "3c197179d55fd9f0",
   "outputs": [],
   "execution_count": 85
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-04T19:46:09.470503Z",
     "start_time": "2024-06-04T19:46:09.430179Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def test_load_Hamiltonians(ps_path, f_name):\n",
    "    U, H_cas, H_hidden, H_with_killer, H_killer_hidden, sol, E_min = planted_workflow.load_Hamiltonian_with_solution(ps_path, f_name)\n",
    "    tbt_1_H_ij, tbt_1_G_ijkl = planted_workflow.chem_spatial_orb_to_phys_spatial_orb(H_cas[1], H_cas[2])\n",
    "    test_spatial_chem_to_phy(H_cas[1], H_cas[2])\n",
    "    tbt_1_hidden_H_ij, tbt_1_hidden_G_ijkl = planted_workflow.chem_spatial_orb_to_phys_spatial_orb(H_hidden[1], H_hidden[2])\n",
    "    \n",
    "    assert np.allclose(np.linalg.norm(tbt_1_H_ij), np.linalg.norm(tbt_1_hidden_H_ij)), \"unitary rotation wrong\"\n",
    "    assert np.allclose(np.linalg.norm(tbt_1_G_ijkl), np.linalg.norm(tbt_1_hidden_G_ijkl)), \"unitary rotation wrong\"\n",
    "    tbt_3_H_ij, tbt_3_G_ijkl = planted_workflow.chem_spatial_orb_to_phys_spatial_orb(H_with_killer[1], H_with_killer[2])\n",
    "    tbt_3_H_ij = np.float64(np.real(tbt_3_H_ij.numpy()))\n",
    "    tbt_3_G_ijkl = np.float64(np.real(tbt_3_G_ijkl.numpy()))\n",
    "    tbt_3_hidden_H_ij, tbt_3_hidden_G_ijkl = planted_workflow.chem_spatial_orb_to_phys_spatial_orb(H_killer_hidden[1], H_killer_hidden[2])\n",
    "    tbt_3_hidden_H_ij = np.float64(np.real(tbt_3_hidden_H_ij))\n",
    "    tbt_3_hidden_G_ijkl = np.float64(np.real(tbt_3_hidden_G_ijkl))\n",
    "    \n",
    "    assert np.allclose(np.linalg.norm(tbt_3_H_ij), np.linalg.norm(tbt_3_hidden_H_ij)), \"unitary rotation wrong\"\n",
    "    assert np.allclose(np.linalg.norm(tbt_3_G_ijkl), np.linalg.norm(tbt_3_hidden_G_ijkl)), \"unitary rotation wrong\"\n",
    "    \n",
    "test_load_Hamiltonians(ps_path, f_name)\n",
    "U, H_cas, H_hidden, H_with_killer, H_killer_hidden, sol, E_min = planted_workflow.load_Hamiltonian_with_solution(ps_path, f_name)\n"
   ],
   "id": "54460c2c6f2b7860",
   "outputs": [],
   "execution_count": 90
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "10491eb38a5d60b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
